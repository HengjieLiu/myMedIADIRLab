{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499b6e74-f571-46b8-9cb4-bb56a26d8ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51be97dc-038d-4847-bd1e-a5b722e5cb33",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'composable_mapping' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcomposable_mapping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcm\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__version__\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'composable_mapping' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "\n",
    "import composable_mapping as cm\n",
    "print(cm.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "744e36bb-f704-4b67-89fa-10d3c2c6044f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Affine' object has no attribute 'transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 309\u001b[0m\n\u001b[1;32m    297\u001b[0m maps \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranslation (y:+8mm, x:-12mm)\u001b[39m\u001b[38;5;124m\"\u001b[39m: mapping_translation(\u001b[38;5;241m8.0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m12.0\u001b[39m, img_cs),\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrotation (15 deg)\u001b[39m\u001b[38;5;124m\"\u001b[39m:              mapping_rotation(\u001b[38;5;241m15.0\u001b[39m, img_cs),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m                                           img_cs),\n\u001b[1;32m    306\u001b[0m }\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, m \u001b[38;5;129;01min\u001b[39;00m maps\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 309\u001b[0m     \u001b[43mshow_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_cs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdose_cs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontour\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 249\u001b[0m, in \u001b[0;36mshow_one\u001b[0;34m(mapping_name, mapping, img_cs, dose_cs, dose_tensor, contour_world)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mshow_one\u001b[39m(mapping_name, mapping, img_cs, dose_cs, dose_tensor, contour_world):\n\u001b[0;32m--> 249\u001b[0m     warped \u001b[38;5;241m=\u001b[39m \u001b[43mwarp_dose_samplable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdose_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdose_cs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m     contour_def \u001b[38;5;241m=\u001b[39m deform_points_world(contour_world, mapping)\n\u001b[1;32m    252\u001b[0m     Hd, Wd \u001b[38;5;241m=\u001b[39m cs_shape(dose_cs)\n",
      "Cell \u001b[0;32mIn[1], line 202\u001b[0m, in \u001b[0;36mwarp_dose_samplable\u001b[0;34m(dose_tensor, dose_cs, mapping, mode)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(cm, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLinearInterpolator\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    200\u001b[0m         vol \u001b[38;5;241m=\u001b[39m vol\u001b[38;5;241m.\u001b[39mmodify_sampler(cm\u001b[38;5;241m.\u001b[39mLinearInterpolator())\n\u001b[0;32m--> 202\u001b[0m warped_mt \u001b[38;5;241m=\u001b[39m \u001b[43mvol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msample_to(dose_cs)\n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m# Materialize to a real tensor robustly (expect [C, H, W])\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(warped_mt, torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/composable_mapping/composable_mapping/composable_mapping.py:861\u001b[0m, in \u001b[0;36mSamplableVolume.__call__\u001b[0;34m(self, coordinates)\u001b[0m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, coordinates: MappableTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m MappableTensor:\n\u001b[0;32m--> 861\u001b[0m     voxel_coordinates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_coordinate_system\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_voxel_coordinates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoordinates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m     sampled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, voxel_coordinates)\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_format\u001b[38;5;241m.\u001b[39mrepresentation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplacements\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/composable_mapping/affine_mapping.py:113\u001b[0m, in \u001b[0;36mAffine.__call__\u001b[0;34m(self, masked_coordinates)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, masked_coordinates: MappableTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m MappableTensor:\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmasked_coordinates\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformation)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Affine' object has no attribute 'transform'"
     ]
    }
   ],
   "source": [
    "# composable-mapping demo: multi-resolution dose + fine contour, 2D\n",
    "# Deforms with translation / rotation / scaling / generic affine\n",
    "# Robust to composable_mapping API differences\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import composable_mapping as cm\n",
    "# We'll use: CoordinateSystem, SamplableVolume, (Affine/affine), Linear/Nearest interpolators, etc.\n",
    "\n",
    "# --- composable-mapping compat helpers ---\n",
    "def cs_grid(cs):\n",
    "    \"\"\"Return CoordinateSystem grid as a MappableTensor (handles property/method).\"\"\"\n",
    "    g = getattr(cs, \"grid\")\n",
    "    return g() if callable(g) else g\n",
    "\n",
    "def cs_shape(cs):\n",
    "    \"\"\"Return (H, W[, ...]) regardless of property/method API.\"\"\"\n",
    "    s = getattr(cs, \"spatial_shape\")\n",
    "    return tuple(s() if callable(s) else s)\n",
    "\n",
    "def cs_spacing(cs):\n",
    "    \"\"\"Return spacing tensor regardless of CPU/GPU variant & property/method API.\"\"\"\n",
    "    f = getattr(cs, \"grid_spacing\", None) or getattr(cs, \"grid_spacing_cpu\", None)\n",
    "    if f is None:\n",
    "        raise AttributeError(\"CoordinateSystem has no grid_spacing[ _cpu ] accessor\")\n",
    "    val = f() if callable(f) else f\n",
    "    return torch.as_tensor(val, dtype=torch.float32)\n",
    "\n",
    "def make_affine(M: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Build a world->world affine mapping robustly across composable_mapping versions.\n",
    "    Tries cm.affine(matrix) first, then class-based APIs.\n",
    "    \"\"\"\n",
    "    if hasattr(cm, \"affine\") and callable(cm.affine):\n",
    "        return cm.affine(M)\n",
    "    if hasattr(cm, \"Affine\"):\n",
    "        A = cm.Affine\n",
    "        if hasattr(A, \"from_matrix\") and callable(A.from_matrix):\n",
    "            # Newer API: single-arg from_matrix(matrix)\n",
    "            return A.from_matrix(M)\n",
    "        # Fallback: some versions may accept a direct constructor\n",
    "        try:\n",
    "            return A(M)\n",
    "        except TypeError as e:\n",
    "            raise RuntimeError(f\"Could not construct Affine with available APIs: {e}\")\n",
    "    raise RuntimeError(\"Composable Mapping: no affine constructor found (missing affine/Affine).\")\n",
    "\n",
    "def channels_first_df_or_none():\n",
    "    \"\"\"Return DataFormat.CHANNELS_FIRST if available, else None.\"\"\"\n",
    "    if hasattr(cm, \"DataFormat\"):\n",
    "        DF = cm.DataFormat\n",
    "        if hasattr(DF, \"CHANNELS_FIRST\"):\n",
    "            return DF.CHANNELS_FIRST\n",
    "    return None\n",
    "\n",
    "\n",
    "# ------------ helpers: coordinate systems & synthetic data ------------\n",
    "\n",
    "def make_coordinate_systems(H=128, W=160, img_spacing_mm=1.0, dose_spacing_mm=0.5):\n",
    "    \"\"\"\n",
    "    Two grids with identical physical FOV:\n",
    "      - image grid: (H, W), spacing = img_spacing_mm\n",
    "      - dose grid:  (Hd, Wd), spacing = dose_spacing_mm\n",
    "    \"\"\"\n",
    "    img_cs = cm.CoordinateSystem.voxel((H, W)).multiply_world(\n",
    "        torch.tensor([img_spacing_mm, img_spacing_mm], dtype=torch.float32)\n",
    "    )\n",
    "\n",
    "    Hd = int(round(H * img_spacing_mm / dose_spacing_mm))\n",
    "    Wd = int(round(W * img_spacing_mm / dose_spacing_mm))\n",
    "\n",
    "    dose_cs = cm.CoordinateSystem.voxel((Hd, Wd)).multiply_world(\n",
    "        torch.tensor([dose_spacing_mm, dose_spacing_mm], dtype=torch.float32)\n",
    "    )\n",
    "\n",
    "    # (Optional) sanity check: same FOV in mm\n",
    "    img_fov = torch.tensor([H * img_spacing_mm, W * img_spacing_mm])\n",
    "    dose_fov = torch.tensor([Hd * dose_spacing_mm, Wd * dose_spacing_mm])\n",
    "    if not torch.allclose(img_fov, dose_fov, atol=1e-3):\n",
    "        print(f\"[warn] FOV mismatch: img {img_fov.tolist()} mm vs dose {dose_fov.tolist()} mm\")\n",
    "\n",
    "    return img_cs, dose_cs\n",
    "\n",
    "\n",
    "def make_synthetic_dose(dose_cs):\n",
    "    \"\"\"\n",
    "    Create a smooth toy 'dose' on the dose grid (same physical FOV as image),\n",
    "    using world-mm coordinates from the coordinate system.\n",
    "\n",
    "    IMPORTANT: return shape [C, H, W] (no batch dim), C=1.\n",
    "    \"\"\"\n",
    "    gyx_mt = cs_grid(dose_cs)\n",
    "    # Materialize to Tensor (handle wrapper types)\n",
    "    if hasattr(gyx_mt, \"generate_values\"):\n",
    "        gyx = gyx_mt.generate_values()\n",
    "    elif isinstance(gyx_mt, torch.Tensor):\n",
    "        gyx = gyx_mt\n",
    "    else:\n",
    "        raise TypeError(\"Unexpected grid type returned by cs_grid(dose_cs)\")\n",
    "\n",
    "    # Expect shape [..., 2, H, W]; split to (y, x) in mm\n",
    "    if gyx.shape[-3] != 2:\n",
    "        raise RuntimeError(f\"Expected coord channels=2 at dim -3, got shape {tuple(gyx.shape)}\")\n",
    "    y = gyx[..., 0, :, :]\n",
    "    x = gyx[..., 1, :, :]\n",
    "\n",
    "    H, W = y.shape[-2:]\n",
    "    sy, sx = cs_spacing(dose_cs)\n",
    "    cy, cx = (sy * H) / 2.0, (sx * W) / 2.0\n",
    "\n",
    "    g1 = torch.exp(-((y - cy) ** 2 + (x - cx) ** 2) / (2.0 * 15.0 ** 2))\n",
    "    g2 = 0.6 * torch.exp(-((y - (0.35 * cy * 2)) ** 2 + (x - (0.65 * cx * 2)) ** 2) / (2.0 * 10.0 ** 2))\n",
    "    dose = (g1 + g2).unsqueeze(0)  # [1, H, W]  (C=1, NO batch dim)\n",
    "    return dose\n",
    "\n",
    "def make_circle_contour(center_yx_mm, radius_mm, step_mm=0.1):\n",
    "    \"\"\"\n",
    "    Return Nx2 world coordinates (in mm) for a circle with arc-length spacing ~step_mm.\n",
    "    center_yx_mm: (y, x) in mm\n",
    "    \"\"\"\n",
    "    circumference = 2 * math.pi * radius_mm\n",
    "    n = max(16, int(round(circumference / step_mm)))\n",
    "    thetas = torch.linspace(0.0, 2.0 * math.pi, n + 1, dtype=torch.float32)[:-1]\n",
    "    y = center_yx_mm[0] + radius_mm * torch.sin(thetas)\n",
    "    x = center_yx_mm[1] + radius_mm * torch.cos(thetas)\n",
    "    return torch.stack([y, x], dim=-1)  # [N, 2] (world coords in mm)\n",
    "\n",
    "# ------------ helpers: building mappings (world->world) ------------\n",
    "\n",
    "def affine_about_point(R_2x2, t_2, pivot_yx):\n",
    "    \"\"\"\n",
    "    Build a 3x3 homogeneous transform acting in world (mm) that rotates/scales about pivot.\n",
    "    x' = T * x_hom, where x=[y,x,1]^T\n",
    "    R_2x2 acts on [y,x]; t_2 is extra translation (world mm).\n",
    "    \"\"\"\n",
    "    T = torch.eye(3, dtype=torch.float32)\n",
    "    T[:2, :2] = R_2x2\n",
    "    T[:2, 2] = t_2\n",
    "    # Conjugate to rotate/scale about pivot (translate to origin -> R -> translate back)\n",
    "    P = torch.eye(3, dtype=torch.float32)\n",
    "    P[:2, 2] = -pivot_yx\n",
    "    Pinv = torch.eye(3, dtype=torch.float32)\n",
    "    Pinv[:2, 2] = pivot_yx\n",
    "    return Pinv @ T @ P  # 3x3\n",
    "\n",
    "def mapping_translation(ty_mm, tx_mm, cs):\n",
    "    M = torch.eye(3, dtype=torch.float32)\n",
    "    M[0, 2] = ty_mm\n",
    "    M[1, 2] = tx_mm\n",
    "    return make_affine(M)  # world->world\n",
    "\n",
    "def mapping_rotation(angle_deg, cs):\n",
    "    theta = math.radians(angle_deg)\n",
    "    R = torch.tensor([[ math.cos(theta), -math.sin(theta)],\n",
    "                      [ math.sin(theta),  math.cos(theta)]], dtype=torch.float32)\n",
    "    H, W = cs_shape(cs)\n",
    "    sy, sx = cs_spacing(cs)\n",
    "    pivot = torch.tensor([H*sy/2.0, W*sx/2.0], dtype=torch.float32)\n",
    "    M = affine_about_point(R, torch.tensor([0.0, 0.0]), pivot)\n",
    "    return make_affine(M)\n",
    "\n",
    "def mapping_scaling(sy_scale, sx_scale, cs):\n",
    "    S = torch.tensor([[sy_scale, 0.0], [0.0, sx_scale]], dtype=torch.float32)\n",
    "    H, W = cs_shape(cs)\n",
    "    sy, sx = cs_spacing(cs)\n",
    "    pivot = torch.tensor([H*sy/2.0, W*sx/2.0], dtype=torch.float32)\n",
    "    M = affine_about_point(S, torch.tensor([0.0, 0.0]), pivot)\n",
    "    return make_affine(M)\n",
    "\n",
    "def mapping_generic_affine(A_2x2, t_2, cs):\n",
    "    H, W = cs_shape(cs)\n",
    "    sy, sx = cs_spacing(cs)\n",
    "    pivot = torch.tensor([H*sy/2.0, W*sx/2.0], dtype=torch.float32)\n",
    "    M = affine_about_point(A_2x2, t_2, pivot)\n",
    "    return make_affine(M)\n",
    "\n",
    "# ------------ helpers: sampling & plotting ------------\n",
    "\n",
    "def warp_dose_samplable(dose_tensor, dose_cs, mapping, mode=\"linear\"):\n",
    "    \"\"\"\n",
    "    Keep output on the *original* dose grid (no resolution change).\n",
    "    We 'pull' the source dose with the coordinate mapping acting in world mm.\n",
    "\n",
    "    dose_tensor MUST be [C, H, W] (no batch dim), C=1.\n",
    "    \"\"\"\n",
    "    data_format = channels_first_df_or_none()\n",
    "    kwargs = {}\n",
    "    if data_format is not None:\n",
    "        kwargs[\"data_format\"] = data_format\n",
    "\n",
    "    vol = cm.SamplableVolume.from_tensor(dose_tensor, dose_cs, **kwargs)\n",
    "    if mode == \"nearest\":\n",
    "        if hasattr(cm, \"NearestInterpolator\"):\n",
    "            vol = vol.modify_sampler(cm.NearestInterpolator())\n",
    "    elif mode == \"linear\":\n",
    "        if hasattr(cm, \"LinearInterpolator\"):\n",
    "            vol = vol.modify_sampler(cm.LinearInterpolator())\n",
    "\n",
    "    warped_mt = vol(mapping).sample_to(dose_cs)\n",
    "    # Materialize to a real tensor robustly (expect [C, H, W])\n",
    "    if isinstance(warped_mt, torch.Tensor):\n",
    "        return warped_mt\n",
    "    if hasattr(warped_mt, \"generate_values\"):\n",
    "        return warped_mt.generate_values()\n",
    "    if hasattr(warped_mt, \"tensor\"):\n",
    "        return warped_mt.tensor\n",
    "    raise TypeError(\"Unexpected return type from sample_to(); cannot materialize Tensor.\")\n",
    "\n",
    "def deform_points_world(pts_yx, mapping):\n",
    "    \"\"\"Apply mapping to NÃ—2 world-mm coordinates.\"\"\"\n",
    "    out = mapping(pts_yx)\n",
    "    # Some versions may return a wrapper; ensure Tensor\n",
    "    if isinstance(out, torch.Tensor):\n",
    "        return out\n",
    "    if hasattr(out, \"generate_values\"):\n",
    "        return out.generate_values()\n",
    "    if hasattr(out, \"tensor\"):\n",
    "        return out.tensor\n",
    "    raise TypeError(\"Unexpected return type from mapping(points); cannot materialize Tensor.\")\n",
    "\n",
    "def plot_grid(ax, cs, mapping=None, every=16, alpha=0.8, lw=0.8):\n",
    "    \"\"\"Draw a (possibly) deformed lattice in world mm coordinates.\"\"\"\n",
    "    H, W = cs_shape(cs)\n",
    "    sy, sx = cs_spacing(cs)\n",
    "    ny = max(2, H // every)\n",
    "    nx = max(2, W // every)\n",
    "    ys = torch.linspace(0, H*sy, ny)\n",
    "    xs = torch.linspace(0, W*sx, nx)\n",
    "\n",
    "    # verticals\n",
    "    for x in xs:\n",
    "        y = torch.linspace(0, H*sy, 200)\n",
    "        line = torch.stack([y, torch.full_like(y, x)], dim=-1)\n",
    "        if mapping is not None:\n",
    "            line = deform_points_world(line, mapping)\n",
    "        ax.plot(line[:,1].numpy(), line[:,0].numpy(), linewidth=lw, alpha=alpha)\n",
    "    # horizontals\n",
    "    for y in ys:\n",
    "        x = torch.linspace(0, W*sx, 200)\n",
    "        line = torch.stack([torch.full_like(x, y), x], dim=-1)\n",
    "        if mapping is not None:\n",
    "            line = deform_points_world(line, mapping)\n",
    "        ax.plot(line[:,1].numpy(), line[:,0].numpy(), linewidth=lw, alpha=alpha)\n",
    "\n",
    "def show_one(mapping_name, mapping, img_cs, dose_cs, dose_tensor, contour_world):\n",
    "    warped = warp_dose_samplable(dose_tensor, dose_cs, mapping, mode=\"linear\")\n",
    "    contour_def = deform_points_world(contour_world, mapping)\n",
    "\n",
    "    Hd, Wd = cs_shape(dose_cs)\n",
    "    sy, sx = cs_spacing(dose_cs)\n",
    "    extent = [0, Wd*sx, Hd*sy, 0]\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(14, 4), constrained_layout=True)\n",
    "\n",
    "    # original\n",
    "    axs[0].imshow(dose_tensor[0].numpy(), extent=extent)  # dose_tensor: [1, H, W]\n",
    "    axs[0].plot(contour_world[:,1].numpy(), contour_world[:,0].numpy(), lw=2)\n",
    "    plot_grid(axs[0], img_cs, mapping=None, every=16, alpha=0.4)\n",
    "    axs[0].set_title(\"Original dose/contour/grid\")\n",
    "    axs[0].set_aspect('equal')\n",
    "\n",
    "    # deformed\n",
    "    axs[1].imshow(warped[0].numpy(), extent=extent)       # warped: [1, H, W]\n",
    "    axs[1].plot(contour_def[:,1].numpy(), contour_def[:,0].numpy(), lw=2)\n",
    "    plot_grid(axs[1], img_cs, mapping=mapping, every=16, alpha=0.4)\n",
    "    axs[1].set_title(f\"Deformed by {mapping_name}\")\n",
    "    axs[1].set_aspect('equal')\n",
    "\n",
    "    # deformation grid alone\n",
    "    plot_grid(axs[2], img_cs, mapping=mapping, every=16, alpha=0.9)\n",
    "    axs[2].set_xlim(0, Wd*sx)\n",
    "    axs[2].set_ylim(Hd*sy, 0)\n",
    "    axs[2].set_title(\"Deformation grid\")\n",
    "    axs[2].set_aspect('equal')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# ------------ main demo ------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    torch.set_default_dtype(torch.float32)\n",
    "\n",
    "    H, W = 128, 160\n",
    "    img_cs, dose_cs = make_coordinate_systems(H, W, img_spacing_mm=1.0, dose_spacing_mm=0.5)\n",
    "\n",
    "    # synthetic dose (high-res grid, same physical FOV); shape [1, H_dose, W_dose]\n",
    "    dose = make_synthetic_dose(dose_cs)\n",
    "\n",
    "    # fine circle contour (0.1 mm arc step) in world mm\n",
    "    center_world = torch.tensor([H*1.0/2.0, W*1.0/2.0])  # image spacing is 1 mm => center in mm\n",
    "    contour = make_circle_contour(center_world, radius_mm=min(H, W)*0.25, step_mm=0.1)\n",
    "\n",
    "    # mappings to test\n",
    "    maps = {\n",
    "        \"translation (y:+8mm, x:-12mm)\": mapping_translation(8.0, -12.0, img_cs),\n",
    "        \"rotation (15 deg)\":              mapping_rotation(15.0, img_cs),\n",
    "        \"scaling (sy=0.9, sx=1.1)\":       mapping_scaling(0.9, 1.1, img_cs),\n",
    "        \"generic affine\":                 mapping_generic_affine(\n",
    "                                              torch.tensor([[0.95, -0.05],\n",
    "                                                            [0.08,  1.02]], dtype=torch.float32),\n",
    "                                              torch.tensor([5.0, -7.0], dtype=torch.float32),\n",
    "                                              img_cs),\n",
    "    }\n",
    "\n",
    "    for name, m in maps.items():\n",
    "        show_one(name, m, img_cs, dose_cs, dose, contour)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
