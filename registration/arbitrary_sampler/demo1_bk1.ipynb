{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e2663d-3922-47c9-aa70-0cdb6650dbcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "884529dc-abba-4b21-a4aa-e59eaa069248",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Affine.from_matrix() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 243\u001b[0m\n\u001b[1;32m    239\u001b[0m contour \u001b[38;5;241m=\u001b[39m make_circle_contour(center_world, radius_mm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmin\u001b[39m(H, W)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.25\u001b[39m, step_mm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m    241\u001b[0m \u001b[38;5;66;03m# mappings to test\u001b[39;00m\n\u001b[1;32m    242\u001b[0m maps \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m--> 243\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranslation (y:+8mm, x:-12mm)\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mmapping_translation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m8.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m12.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_cs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrotation (15 deg)\u001b[39m\u001b[38;5;124m\"\u001b[39m:              mapping_rotation(\u001b[38;5;241m15.0\u001b[39m, img_cs),\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscaling (sy=0.9, sx=1.1)\u001b[39m\u001b[38;5;124m\"\u001b[39m:       mapping_scaling(\u001b[38;5;241m0.9\u001b[39m, \u001b[38;5;241m1.1\u001b[39m, img_cs),\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneric affine\u001b[39m\u001b[38;5;124m\"\u001b[39m:                 mapping_generic_affine(\n\u001b[1;32m    247\u001b[0m                                           torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m0.95\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.05\u001b[39m],\n\u001b[1;32m    248\u001b[0m                                                         [\u001b[38;5;241m0.08\u001b[39m,  \u001b[38;5;241m1.02\u001b[39m]]),\n\u001b[1;32m    249\u001b[0m                                           torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m5.0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m7.0\u001b[39m]), img_cs),\n\u001b[1;32m    250\u001b[0m }\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, m \u001b[38;5;129;01min\u001b[39;00m maps\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    253\u001b[0m     show_one(name, m, img_cs, dose_cs, dose, contour)\n",
      "Cell \u001b[0;32mIn[1], line 126\u001b[0m, in \u001b[0;36mmapping_translation\u001b[0;34m(ty_mm, tx_mm, cs)\u001b[0m\n\u001b[1;32m    124\u001b[0m M[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m ty_mm\n\u001b[1;32m    125\u001b[0m M[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m tx_mm\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAffine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Affine.from_matrix() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "# composable-mapping demo: multi-resolution dose + fine contour, 2D\n",
    "# Deforms with translation / rotation / scaling / generic affine\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import composable_mapping as cm\n",
    "# API we’ll use: CoordinateSystem, Affine/affine, SamplableVolume, DataFormat, etc.\n",
    "# See docs index listing these symbols.  # (Docs: honkamj.github.io/composable-mapping) \n",
    "\n",
    "# --- composable-mapping compat helpers ---\n",
    "def cs_grid(cs):\n",
    "    \"\"\"Return CoordinateSystem grid as a MappableTensor (handles property/method).\"\"\"\n",
    "    g = getattr(cs, \"grid\")\n",
    "    return g() if callable(g) else g\n",
    "\n",
    "def cs_shape(cs):\n",
    "    \"\"\"Return (H, W[, ...]) regardless of property/method API.\"\"\"\n",
    "    s = getattr(cs, \"spatial_shape\")\n",
    "    return s() if callable(s) else s\n",
    "\n",
    "def cs_spacing(cs):\n",
    "    \"\"\"Return spacing tensor regardless of CPU/GPU variant & property/method API.\"\"\"\n",
    "    f = getattr(cs, \"grid_spacing\", None) or getattr(cs, \"grid_spacing_cpu\", None)\n",
    "    if f is None:\n",
    "        raise AttributeError(\"CoordinateSystem has no grid_spacing[ _cpu ] accessor\")\n",
    "    return f() if callable(f) else f\n",
    "\n",
    "\n",
    "# ------------ helpers: coordinate systems & synthetic data ------------\n",
    "\n",
    "def make_coordinate_systems(H=128, W=160, img_spacing_mm=1.0, dose_spacing_mm=0.5):\n",
    "    \"\"\"\n",
    "    Two grids with identical physical FOV:\n",
    "      - image grid: (H, W), spacing = img_spacing_mm\n",
    "      - dose grid:  (Hd, Wd), spacing = dose_spacing_mm\n",
    "    \"\"\"\n",
    "    # Base image CS: voxel grid scaled to world mm (origin 0, identity orientation)\n",
    "    img_cs = cm.CoordinateSystem.voxel((H, W)).multiply_world(\n",
    "        torch.tensor([img_spacing_mm, img_spacing_mm], dtype=torch.float32)\n",
    "    )\n",
    "\n",
    "    # Choose dose shape so that physical sizes match\n",
    "    Hd = int(round(H * img_spacing_mm / dose_spacing_mm))\n",
    "    Wd = int(round(W * img_spacing_mm / dose_spacing_mm))\n",
    "\n",
    "    dose_cs = cm.CoordinateSystem.voxel((Hd, Wd)).multiply_world(\n",
    "        torch.tensor([dose_spacing_mm, dose_spacing_mm], dtype=torch.float32)\n",
    "    )\n",
    "\n",
    "    # (Optional) sanity check: same FOV in mm\n",
    "    img_fov = torch.tensor([H * img_spacing_mm, W * img_spacing_mm])\n",
    "    dose_fov = torch.tensor([Hd * dose_spacing_mm, Wd * dose_spacing_mm])\n",
    "    if not torch.allclose(img_fov, dose_fov, atol=1e-3):\n",
    "        print(f\"[warn] FOV mismatch: img {img_fov.tolist()} mm vs dose {dose_fov.tolist()} mm\")\n",
    "\n",
    "    return img_cs, dose_cs\n",
    "\n",
    "\n",
    "def gaussian2d(grid_yx, mu_yx, sigma_yx):\n",
    "    y, x = grid_yx[..., 0], grid_yx[..., 1]\n",
    "    my, mx = mu_yx\n",
    "    sy, sx = sigma_yx\n",
    "    return torch.exp(-0.5 * (((y - my)/sy)**2 + ((x - mx)/sx)**2))\n",
    "\n",
    "def make_synthetic_dose(dose_cs):\n",
    "    \"\"\"\n",
    "    Create a smooth toy 'dose' on the dose grid (same physical FOV as image),\n",
    "    using world-mm coordinates from the coordinate system.\n",
    "    \"\"\"\n",
    "    # World grid as a MappableTensor\n",
    "    gyx_mt = cs_grid(dose_cs)                          # <-- NO parentheses\n",
    "    gyx = gyx_mt.generate_values()                      # materialize to Tensor\n",
    "\n",
    "    # Expect shape [*, 2, H, W]; split to (y, x) in mm\n",
    "    if gyx.shape[-3] != 2:\n",
    "        raise RuntimeError(f\"Expected coord channels=2 at dim -3, got shape {gyx.shape}\")\n",
    "    y = gyx[..., 0, :, :]\n",
    "    x = gyx[..., 1, :, :]\n",
    "\n",
    "    # A couple of Gaussians summed\n",
    "    H, W = y.shape[-2:]\n",
    "    cy, cx = (cs_spacing(dose_cs)[0] * H) / 2.0, (cs_spacing(dose_cs)[1] * W) / 2.0\n",
    "    g1 = torch.exp(-((y - cy) ** 2 + (x - cx) ** 2) / (2.0 * 15.0 ** 2))\n",
    "    g2 = 0.6 * torch.exp(-((y - (0.35 * cy * 2)) ** 2 + (x - (0.65 * cx * 2)) ** 2) / (2.0 * 10.0 ** 2))\n",
    "    dose = (g1 + g2).unsqueeze(0).unsqueeze(0)         # [1,1,H,W]\n",
    "    return dose\n",
    "\n",
    "def make_circle_contour(center_yx_mm, radius_mm, step_mm=0.1):\n",
    "    \"\"\"\n",
    "    Return Nx2 world coordinates (in mm) for a circle with arc-length spacing ~step_mm.\n",
    "    center_yx_mm: (y, x) in mm\n",
    "    \"\"\"\n",
    "    circumference = 2 * math.pi * radius_mm\n",
    "    n = max(16, int(round(circumference / step_mm)))\n",
    "    # torch.linspace on some versions doesn't support endpoint=. Emulate [0, 2π) by slicing off last sample.\n",
    "    thetas = torch.linspace(0.0, 2.0 * math.pi, n + 1, dtype=torch.float32)[:-1]\n",
    "    y = center_yx_mm[0] + radius_mm * torch.sin(thetas)\n",
    "    x = center_yx_mm[1] + radius_mm * torch.cos(thetas)\n",
    "    return torch.stack([y, x], dim=-1)  # [N, 2] (world coords in mm)\n",
    "\n",
    "# ------------ helpers: building mappings (world->world) ------------\n",
    "\n",
    "def affine_about_point(R_2x2, t_2, pivot_yx):\n",
    "    \"\"\"\n",
    "    Build a 3x3 homogeneous transform acting in world (mm) that rotates/scales about pivot.\n",
    "    x' = T * x_hom, where x=[y,x,1]^T\n",
    "    R_2x2 acts on [y,x]; t_2 is extra translation (world mm).\n",
    "    \"\"\"\n",
    "    T = torch.eye(3, dtype=torch.float32)\n",
    "    T[:2, :2] = R_2x2\n",
    "    T[:2, 2] = t_2\n",
    "    # Conjugate to rotate/scale about pivot (translate to origin -> R -> translate back)\n",
    "    P = torch.eye(3, dtype=torch.float32)\n",
    "    P[:2, 2] = -pivot_yx\n",
    "    Pinv = torch.eye(3, dtype=torch.float32)\n",
    "    Pinv[:2, 2] = pivot_yx\n",
    "    return Pinv @ T @ P  # 3x3\n",
    "\n",
    "def mapping_translation(ty_mm, tx_mm, cs):\n",
    "    M = torch.eye(3, dtype=torch.float32)\n",
    "    M[0, 2] = ty_mm\n",
    "    M[1, 2] = tx_mm\n",
    "    return cm.Affine.from_matrix(M, cs)  # world->world\n",
    "\n",
    "def mapping_rotation(angle_deg, cs):\n",
    "    theta = math.radians(angle_deg)\n",
    "    R = torch.tensor([[ math.cos(theta), -math.sin(theta)],\n",
    "                      [ math.sin(theta),  math.cos(theta)]], dtype=torch.float32)\n",
    "    # rotate about image center in world units\n",
    "    H, W = cs.spatial_shape()\n",
    "    spacing_y, spacing_x = cs.grid_spacing()\n",
    "    pivot = torch.tensor([H*spacing_y/2.0, W*spacing_x/2.0], dtype=torch.float32)\n",
    "    M = affine_about_point(R, torch.tensor([0.0, 0.0]), pivot)\n",
    "    return cm.Affine.from_matrix(M, cs)\n",
    "\n",
    "def mapping_scaling(sy, sx, cs):\n",
    "    S = torch.tensor([[sy, 0.0], [0.0, sx]], dtype=torch.float32)\n",
    "    H, W = cs.spatial_shape()\n",
    "    spacing_y, spacing_x = cs.grid_spacing()\n",
    "    pivot = torch.tensor([H*spacing_y/2.0, W*spacing_x/2.0], dtype=torch.float32)\n",
    "    M = affine_about_point(S, torch.tensor([0.0, 0.0]), pivot)\n",
    "    return cm.Affine.from_matrix(M, cs)\n",
    "\n",
    "def mapping_generic_affine(A_2x2, t_2, cs):\n",
    "    H, W = cs.spatial_shape()\n",
    "    spacing_y, spacing_x = cs.grid_spacing()\n",
    "    pivot = torch.tensor([H*spacing_y/2.0, W*spacing_x/2.0], dtype=torch.float32)\n",
    "    M = affine_about_point(A_2x2, t_2, pivot)\n",
    "    return cm.Affine.from_matrix(M, cs)\n",
    "\n",
    "# ------------ helpers: sampling & plotting ------------\n",
    "\n",
    "def warp_dose_samplable(dose_tensor, dose_cs, mapping, mode=\"linear\"):\n",
    "    \"\"\"\n",
    "    Keep output on the *original* dose grid (no resolution change).\n",
    "    We 'pull' the source dose with the coordinate mapping acting in world mm.\n",
    "    \"\"\"\n",
    "    # Wrap as a samplable volume to use the library’s sampling path\n",
    "    vol = cm.SamplableVolume.from_tensor(dose_tensor, dose_cs)\n",
    "    if mode == \"nearest\":\n",
    "        vol = vol.modify_sampler(cm.NearestInterpolator())\n",
    "    elif mode == \"linear\":\n",
    "        vol = vol.modify_sampler(cm.LinearInterpolator())\n",
    "    # Pull to the same grid: evaluate source at mapped coords\n",
    "    warped = vol(mapping).sample_to(dose_cs)   # (docs list __call__/sample_to on SamplableVolume/ComposableMapping)\n",
    "    return warped  # torch tensor [1,1,H,W]\n",
    "\n",
    "def deform_points_world(pts_yx, mapping):\n",
    "    \"\"\"Apply mapping to N×2 world-mm coordinates.\"\"\"\n",
    "    # ComposableMapping.__call__ supports sampling given coordinates (docs list __call__)\n",
    "    return mapping(pts_yx)\n",
    "\n",
    "def plot_grid(ax, cs, mapping=None, every=16, alpha=0.8, lw=0.8):\n",
    "    \"\"\"Draw a deformed lattice in world mm coordinates.\"\"\"\n",
    "    H, W = cs.spatial_shape()\n",
    "    sy, sx = cs.grid_spacing()\n",
    "    ny = max(2, H // every)\n",
    "    nx = max(2, W // every)\n",
    "    ys = torch.linspace(0, H*sy, ny)\n",
    "    xs = torch.linspace(0, W*sx, nx)\n",
    "\n",
    "    # verticals\n",
    "    for x in xs:\n",
    "        y = torch.linspace(0, H*sy, 200)\n",
    "        line = torch.stack([y, torch.full_like(y, x)], dim=-1)\n",
    "        if mapping is not None:\n",
    "            line = mapping(line)\n",
    "        ax.plot(line[:,1].numpy(), line[:,0].numpy(), linewidth=lw, alpha=alpha)\n",
    "    # horizontals\n",
    "    for y in ys:\n",
    "        x = torch.linspace(0, W*sx, 200)\n",
    "        line = torch.stack([torch.full_like(x, y), x], dim=-1)\n",
    "        if mapping is not None:\n",
    "            line = mapping(line)\n",
    "        ax.plot(line[:,1].numpy(), line[:,0].numpy(), linewidth=lw, alpha=alpha)\n",
    "\n",
    "def show_one(mapping_name, mapping, img_cs, dose_cs, dose_tensor, contour_world):\n",
    "    warped = warp_dose_samplable(dose_tensor, dose_cs, mapping, mode=\"linear\")\n",
    "    contour_def = deform_points_world(contour_world, mapping)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(14, 4), constrained_layout=True)\n",
    "    # original\n",
    "    axs[0].imshow(dose_tensor[0,0].numpy(), extent=[0, dose_cs.spatial_shape()[1]*dose_cs.grid_spacing()[1],\n",
    "                                                     dose_cs.spatial_shape()[0]*dose_cs.grid_spacing()[0], 0])\n",
    "    axs[0].plot(contour_world[:,1].numpy(), contour_world[:,0].numpy(), lw=2)\n",
    "    plot_grid(axs[0], img_cs, mapping=None, every=16, alpha=0.4)\n",
    "    axs[0].set_title(\"Original dose/contour/grid\"); axs[0].set_aspect('equal')\n",
    "\n",
    "    # deformed\n",
    "    axs[1].imshow(warped[0,0].numpy(), extent=[0, dose_cs.spatial_shape()[1]*dose_cs.grid_spacing()[1],\n",
    "                                               dose_cs.spatial_shape()[0]*dose_cs.grid_spacing()[0], 0])\n",
    "    axs[1].plot(contour_def[:,1].numpy(), contour_def[:,0].numpy(), lw=2)\n",
    "    plot_grid(axs[1], img_cs, mapping=mapping, every=16, alpha=0.4)\n",
    "    axs[1].set_title(f\"Deformed by {mapping_name}\"); axs[1].set_aspect('equal')\n",
    "\n",
    "    # deformation grid alone\n",
    "    plot_grid(axs[2], img_cs, mapping=mapping, every=16, alpha=0.9)\n",
    "    axs[2].set_xlim(0, dose_cs.spatial_shape()[1]*dose_cs.grid_spacing()[1])\n",
    "    axs[2].set_ylim(dose_cs.spatial_shape()[0]*dose_cs.grid_spacing()[0], 0)\n",
    "    axs[2].set_title(\"Deformation grid\"); axs[2].set_aspect('equal')\n",
    "    plt.show()\n",
    "\n",
    "# ------------ main demo ------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    torch.set_default_dtype(torch.float32)\n",
    "\n",
    "    H, W = 128, 160\n",
    "    img_cs, dose_cs = make_coordinate_systems(H, W, img_spacing_mm=1.0, dose_spacing_mm=0.5)\n",
    "\n",
    "    # synthetic dose (high-res grid, same physical FOV)\n",
    "    dose = make_synthetic_dose(dose_cs)  # [1,1,Hdose,Wdose]\n",
    "\n",
    "    # fine circle contour (0.1 mm arc step) in world mm\n",
    "    center_world = torch.tensor([H*1.0/2.0, W*1.0/2.0])  # since image spacing is 1 mm\n",
    "    contour = make_circle_contour(center_world, radius_mm=min(H, W)*0.25, step_mm=0.1)\n",
    "\n",
    "    # mappings to test\n",
    "    maps = {\n",
    "        \"translation (y:+8mm, x:-12mm)\": mapping_translation(8.0, -12.0, img_cs),\n",
    "        \"rotation (15 deg)\":              mapping_rotation(15.0, img_cs),\n",
    "        \"scaling (sy=0.9, sx=1.1)\":       mapping_scaling(0.9, 1.1, img_cs),\n",
    "        \"generic affine\":                 mapping_generic_affine(\n",
    "                                              torch.tensor([[0.95, -0.05],\n",
    "                                                            [0.08,  1.02]]),\n",
    "                                              torch.tensor([5.0, -7.0]), img_cs),\n",
    "    }\n",
    "\n",
    "    for name, m in maps.items():\n",
    "        show_one(name, m, img_cs, dose_cs, dose, contour)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359de5e6-9df9-486b-b1a3-fe36f0d5955d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
